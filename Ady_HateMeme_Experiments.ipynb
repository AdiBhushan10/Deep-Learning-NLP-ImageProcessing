{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Ady_HateMeme_Distilbert_ResNext101_Experiments.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e7f89540ec0942afaba246fb6060fbe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_da851d245266445ca5232c23f5a4f4b9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d4c19dc4995e475cb2a3febb0d5e3d00",
              "IPY_MODEL_ec9d322a075147e9a8bbacfde5a9b1dc"
            ]
          }
        },
        "da851d245266445ca5232c23f5a4f4b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d4c19dc4995e475cb2a3febb0d5e3d00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_40985f8c58fc4eadab06e0487f499540",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9044e95eafcb457abb69ff357db7adfd"
          }
        },
        "ec9d322a075147e9a8bbacfde5a9b1dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8309932a8bd1485d85730c7826030997",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:03&lt;00:00, 71.2kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e35b2aa849a04d24a2a7ba94e3ece32b"
          }
        },
        "40985f8c58fc4eadab06e0487f499540": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9044e95eafcb457abb69ff357db7adfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8309932a8bd1485d85730c7826030997": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e35b2aa849a04d24a2a7ba94e3ece32b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c297f2e39dbf4b1698c0e67f658553fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b93a0997e45a47d9b532ef98b1f814bb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d4630bc7f88942469e6598c94966c868",
              "IPY_MODEL_a350ad83c03d4a32b14ad9cb38947406"
            ]
          }
        },
        "b93a0997e45a47d9b532ef98b1f814bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d4630bc7f88942469e6598c94966c868": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_efa588439ea949e98d32a4b64d3d2801",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1df566f358ce4ef698b2aeb10dedee25"
          }
        },
        "a350ad83c03d4a32b14ad9cb38947406": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_11982532af5c404b89095d2fc057135a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:01&lt;00:00, 299kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fe87e8e6ad9f4962a610a8b07f7bd6b1"
          }
        },
        "efa588439ea949e98d32a4b64d3d2801": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1df566f358ce4ef698b2aeb10dedee25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "11982532af5c404b89095d2fc057135a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fe87e8e6ad9f4962a610a8b07f7bd6b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "740988ffa14544c0a3cf49177b8364e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4405009e340e4bcd9a78515a4f3e213d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5543ad71afd24a73978f734b1c59cfa5",
              "IPY_MODEL_cd2c161ae25c4996882f79337cee081d"
            ]
          }
        },
        "4405009e340e4bcd9a78515a4f3e213d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5543ad71afd24a73978f734b1c59cfa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_85f7fa9da7264e46ab2fec8662d377e0",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_02121998391d46399e9f10b173d2750b"
          }
        },
        "cd2c161ae25c4996882f79337cee081d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4c962bf6d5b9474ca96c9928e9be2dff",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 33.6B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_37a848324d64465cbeff237054761e57"
          }
        },
        "85f7fa9da7264e46ab2fec8662d377e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "02121998391d46399e9f10b173d2750b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4c962bf6d5b9474ca96c9928e9be2dff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "37a848324d64465cbeff237054761e57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a14347a374724d02b1bd93710d7545ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5b97ccbadd864e9f99a326c7c5d8b010",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_29c722809e924773aff4880b5394bf59",
              "IPY_MODEL_9b7cae399f5441668d5e7b8e7984e720"
            ]
          }
        },
        "5b97ccbadd864e9f99a326c7c5d8b010": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "29c722809e924773aff4880b5394bf59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d837211c41994cdf86ba0d0d326a4681",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 442,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 442,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_32b4a0b791bd4dc6b95a2e5d3aad02cb"
          }
        },
        "9b7cae399f5441668d5e7b8e7984e720": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_326f527565ca4f6585d8b8e0d44bcc0d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 442/442 [00:00&lt;00:00, 12.6kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4a51f7d4b0aa479cad31aff1bd41a221"
          }
        },
        "d837211c41994cdf86ba0d0d326a4681": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "32b4a0b791bd4dc6b95a2e5d3aad02cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "326f527565ca4f6585d8b8e0d44bcc0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4a51f7d4b0aa479cad31aff1bd41a221": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "101f450cf7314744bbfdb696b88a7d0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0770fc20e84a4f339a22362f24ea9d84",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_be7b473be67b476ab7968a576e817bf0",
              "IPY_MODEL_a6495f85f53348c38698518aea817e13"
            ]
          }
        },
        "0770fc20e84a4f339a22362f24ea9d84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "be7b473be67b476ab7968a576e817bf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9854974399564fa48966dba15e671706",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 267967963,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 267967963,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3aaa3f34b86c4892a59c56edaf929d6b"
          }
        },
        "a6495f85f53348c38698518aea817e13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fe3ccd6ccdf14fc59b3efcdceebe7419",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 268M/268M [01:43&lt;00:00, 2.58MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e61e84a2e96345f3add0338e874dcb40"
          }
        },
        "9854974399564fa48966dba15e671706": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3aaa3f34b86c4892a59c56edaf929d6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fe3ccd6ccdf14fc59b3efcdceebe7419": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e61e84a2e96345f3add0338e874dcb40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "fNxB0trzaP8i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6696baa4-5b6e-4cbb-e22e-ef911f6219ee"
      },
      "source": [
        "# mount google drive to colab for dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/DL_PROJECT')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MRn4QyBpUM7",
        "outputId": "4eb0134d-2e7f-46e8-d54f-b99f63a4d218"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.9.1-py3-none-any.whl (2.6 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.6 MB 15.3 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895 kB 50.2 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 636 kB 69.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3 MB 51.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
            "Collecting huggingface-hub==0.0.12\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.12 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S86eNBVm5pWj",
        "outputId": "e6387ef8-0f5b-422a-f8f8-938211165109"
      },
      "source": [
        "!pip install jsonlines"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting jsonlines\n",
            "  Downloading jsonlines-2.0.0-py3-none-any.whl (6.3 kB)\n",
            "Installing collected packages: jsonlines\n",
            "Successfully installed jsonlines-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KGC5duQNTIK",
        "outputId": "e3c3fd04-6a6e-406c-be69-d537e1331ac9"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.2 MB 5.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213,
          "referenced_widgets": [
            "e7f89540ec0942afaba246fb6060fbe9",
            "da851d245266445ca5232c23f5a4f4b9",
            "d4c19dc4995e475cb2a3febb0d5e3d00",
            "ec9d322a075147e9a8bbacfde5a9b1dc",
            "40985f8c58fc4eadab06e0487f499540",
            "9044e95eafcb457abb69ff357db7adfd",
            "8309932a8bd1485d85730c7826030997",
            "e35b2aa849a04d24a2a7ba94e3ece32b",
            "c297f2e39dbf4b1698c0e67f658553fb",
            "b93a0997e45a47d9b532ef98b1f814bb",
            "d4630bc7f88942469e6598c94966c868",
            "a350ad83c03d4a32b14ad9cb38947406",
            "efa588439ea949e98d32a4b64d3d2801",
            "1df566f358ce4ef698b2aeb10dedee25",
            "11982532af5c404b89095d2fc057135a",
            "fe87e8e6ad9f4962a610a8b07f7bd6b1",
            "740988ffa14544c0a3cf49177b8364e6",
            "4405009e340e4bcd9a78515a4f3e213d",
            "5543ad71afd24a73978f734b1c59cfa5",
            "cd2c161ae25c4996882f79337cee081d",
            "85f7fa9da7264e46ab2fec8662d377e0",
            "02121998391d46399e9f10b173d2750b",
            "4c962bf6d5b9474ca96c9928e9be2dff",
            "37a848324d64465cbeff237054761e57",
            "a14347a374724d02b1bd93710d7545ca",
            "5b97ccbadd864e9f99a326c7c5d8b010",
            "29c722809e924773aff4880b5394bf59",
            "9b7cae399f5441668d5e7b8e7984e720",
            "d837211c41994cdf86ba0d0d326a4681",
            "32b4a0b791bd4dc6b95a2e5d3aad02cb",
            "326f527565ca4f6585d8b8e0d44bcc0d",
            "4a51f7d4b0aa479cad31aff1bd41a221"
          ]
        },
        "id": "2Tej6vi6XovL",
        "outputId": "be41e51d-44cf-4c87-affa-24f629d9eeaa"
      },
      "source": [
        "from PIL import Image\n",
        "#import json\n",
        "import jsonlines\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "from torch.utils import data\n",
        "from torchvision import transforms, datasets, models\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "from collections import defaultdict\n",
        "\n",
        "#Load the BERT tokenizer.\n",
        "import transformers\n",
        "from transformers import DistilBertTokenizerFast #DebertaTokenizerFast #BertTokenizer\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased', do_lower_case=True)#DebertaTokenizerFast.from_pretrained('microsoft/deberta-base', do_lower_case=True) #BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7f89540ec0942afaba246fb6060fbe9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c297f2e39dbf4b1698c0e67f658553fb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "740988ffa14544c0a3cf49177b8364e6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_wâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a14347a374724d02b1bd93710d7545ca",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkwdaKj1wZRk"
      },
      "source": [
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waKkLLBbXvpi"
      },
      "source": [
        "'''\n",
        "tokenize all of the sentences and map the tokens to their word IDs.\n",
        "'''\n",
        "def tokenize(sequences):\n",
        "    \n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    # For every caption...\n",
        "    for seq in sequences:\n",
        "        '''\n",
        "        `encode_plus` will:\n",
        "          (1) Tokenize the caption.\n",
        "          (2) Prepend the `[CLS]` token to the start.\n",
        "          (3) Append the `[SEP]` token to the end.\n",
        "          (4) Map tokens to their IDs.\n",
        "          (5) Pad or truncate the sentence to `max_length`\n",
        "          (6) Create attention masks for [PAD] tokens.\n",
        "        '''\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            seq,                       # Sentence to encode.\n",
        "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                            max_length = 48,           # Pad & truncate all sentences.\n",
        "                            truncation=True,\n",
        "                            pad_to_max_length = True,\n",
        "                            return_attention_mask = True,   # Construct attn. masks.\n",
        "                            return_tensors = 'pt'      # Return pytorch tensors.\n",
        "                       )\n",
        "\n",
        "        # Add the encoded sentence to the list.    \n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "        # And its attention mask (simply differentiates padding from non-padding).\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    # Convert the lists into tensors.\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    \n",
        "    \n",
        "    return input_ids, attention_masks"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAHkINaHh1fD"
      },
      "source": [
        "# Data Augmentation - Images are cropped or flipped based on weather we are using test/val or training set\n",
        "\n",
        "# Dataloader Classes\n",
        "\n",
        "class mytestdataset():    \n",
        "\n",
        "    def __init__(self, classification_list, name):\n",
        "\n",
        "        super(mytestdataset).__init__()\n",
        "        \n",
        "        self.X = []\n",
        "        self.Cap = []\n",
        "        self.Imagename = []\n",
        "\n",
        "        with jsonlines.open(classification_list) as f:\n",
        "          f1 = []\n",
        "          for line in f:\n",
        "            f1.append(line)\n",
        "          for line1 in f1:\n",
        "            path =  line1['img']\n",
        "            self.X.append('/content/drive/My Drive/DL_PROJECT/hateful_memes/hateful_memes/'+path)\n",
        "            self.Cap.append(line1['text'])\n",
        "            self.Imagename.append(line1['id'])\n",
        "        \n",
        "        #Tokenize all of the captions and map the tokens to their word IDs, and get respective attention masks.\n",
        "        \n",
        "        self.input_ids, self.attention_masks = tokenize(self.Cap)\n",
        "        \n",
        "        # Data Augmentation - Input Image Transformation\n",
        "        \n",
        "        self.transform = transforms.Compose([   transforms.Resize(256),\n",
        "                                                transforms.CenterCrop(224),\n",
        "                                                transforms.ToTensor(),\n",
        "                                                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                                     std=[0.229, 0.224, 0.225])\n",
        "                                            ])\n",
        "    \n",
        "    def __getitem__(self,index):\n",
        "\n",
        "        '''\n",
        "        Image\n",
        "        '''\n",
        "        image = self.X[index]\n",
        "                \n",
        "        image = Image.open(image).convert('RGB') #.replace('img/', '')))\n",
        "               \n",
        "        image = self.transform(image)\n",
        "        \n",
        "        '''\n",
        "        For Captions, Input ids, Attention mask and Imagename\n",
        "        '''\n",
        "        caption = self.Cap[index]\n",
        "        input_id = self.input_ids[index]\n",
        "        attention_masks = self.attention_masks[index]\n",
        "        Imagename = self.Imagename[index]\n",
        "        return image, caption, input_id, attention_masks, Imagename\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "\n",
        "class mydataset():    \n",
        "\n",
        "    def __init__(self, classification_list, name):\n",
        "\n",
        "        super(mydataset).__init__()\n",
        "        \n",
        "        self.X = []\n",
        "        self.Cap = []\n",
        "        self.Y = []\n",
        "\n",
        "        with jsonlines.open(classification_list) as f:\n",
        "          f1 = []\n",
        "          for line in f:\n",
        "            f1.append(line)\n",
        "          for line1 in f1:\n",
        "            path =  line1['img']\n",
        "            self.X.append('/content/drive/My Drive/DL_PROJECT/hateful_memes/hateful_memes/'+path)\n",
        "            self.Cap.append(line1['text'])\n",
        "            self.Y.append(line1['label'])\n",
        "\n",
        "        '''\n",
        "        Tokenize all of the captions and map the tokens to thier word IDs, and get respective attention masks.\n",
        "        '''\n",
        "        self.input_ids, self.attention_masks = tokenize(self.Cap)\n",
        "        \n",
        "        '''\n",
        "        Image Transforms\n",
        "        '''\n",
        "        if name in ['valid','test']:\n",
        "            self.transform = transforms.Compose([transforms.Resize(384),\n",
        "                                                 transforms.CenterCrop(256),\n",
        "                                                transforms.ToTensor(),\n",
        "                                                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                                    std=[0.229, 0.224, 0.225])\n",
        "                                                ])\n",
        "        else:\n",
        "            self.transform = transforms.Compose([transforms.Resize(256),\n",
        "                                                 transforms.RandomCrop(224),\n",
        "                                                transforms.RandomHorizontalFlip(),\n",
        "                                                transforms.ToTensor(),\n",
        "                                                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                                    std=[0.229, 0.224, 0.225])\n",
        "                                                                                            ])\n",
        "    \n",
        "    def __getitem__(self,index):\n",
        "        #For Image and Label\n",
        "        image = self.X[index]\n",
        "        image = Image.open(image).convert('RGB') #.replace('img/', '')))\n",
        "        image = self.transform(image)\n",
        "        label = float(self.Y[index])\n",
        "        \n",
        "        #For Captions, Input ids and Attention mask\n",
        "        caption = self.Cap[index]\n",
        "        input_id = self.input_ids[index]\n",
        "        attention_masks = self.attention_masks[index] \n",
        "        return image, caption, input_id, attention_masks, torch.as_tensor(label).long()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUNISXygsX37"
      },
      "source": [
        "# Wide ResNet or RexNext\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
        "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
        "                 norm_layer=None):\n",
        "        super(ResNet, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        self._norm_layer = norm_layer\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.dilation = 1\n",
        "        if replace_stride_with_dilation is None:\n",
        "            # each element in the tuple indicates if we should replace\n",
        "            # the 2x2 stride with a dilated convolution instead\n",
        "            replace_stride_with_dilation = [False, False, False]\n",
        "        if len(replace_stride_with_dilation) != 3:\n",
        "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
        "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = norm_layer(self.inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[0])\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[1])\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[2])\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "#         self.batchnorm = nn.BatchNorm1d(num_features=512 * block.expansion)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        previous_dilation = self.dilation\n",
        "        if dilate:\n",
        "            self.dilation *= stride\n",
        "            stride = 1\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                norm_layer(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
        "                            self.base_width, previous_dilation, norm_layer))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
        "                                base_width=self.base_width, dilation=self.dilation,\n",
        "                                norm_layer=norm_layer))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _forward_impl(self, x):\n",
        "        # See note [TorchScript super()]\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)        \n",
        "        embedding = x\n",
        "        x = self.fc(embedding)\n",
        "           \n",
        "#         return x\n",
        "        return x, embedding\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self._forward_impl(x)\n",
        "'''\n",
        "def ResNet50(img_channels=3,num_classes=1000):\n",
        "     \"\"\"ResNet-50 model from\n",
        "     `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "     Args:\n",
        "         pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "         progress (bool): If True, displays a progress bar of the download to stderr\n",
        "     \"\"\"\n",
        "     return ResNet(BasicBlock, [3, 4, 6, 3], img_channels,num_classes)\n",
        "\n",
        "'''\n",
        "'''\n",
        "def resnext101_32x8d(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"ResNeXt-101 32x8d model from\n",
        "    `\"Aggregated Residual Transformation for Deep Neural Networks\" <https://arxiv.org/pdf/1611.05431.pdf>`_\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    kwargs['groups'] = 32\n",
        "    kwargs['width_per_group'] = 8\n",
        "    return _resnet('resnext101_32x8d', Bottleneck, [3, 4, 23, 3],\n",
        "                   pretrained, progress, **kwargs)\n",
        "'''\n",
        "def wide_resnet101_2(pretrained=False, progress=True, **kwargs):\n",
        "      r\"\"\"Wide ResNet-101-2 model from\n",
        "      `\"Wide Residual Networks\" <https://arxiv.org/pdf/1605.07146.pdf>`_\n",
        "      The model is the same as ResNet except for the bottleneck number of channels\n",
        "      which is twice larger in every block. The number of channels in outer 1x1\n",
        "      convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048\n",
        "      channels, and in Wide ResNet-50-2 has 2048-1024-2048.\n",
        "      Args:\n",
        "          pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "          progress (bool): If True, displays a progress bar of the download to stderr\n",
        "      \"\"\"\n",
        "      kwargs['width_per_group'] = 64 * 2\n",
        "      return _resnet('wide_resnet101_2', Bottleneck, [3, 4, 23, 3],\n",
        "                      pretrained, progress, **kwargs) \n",
        "def _resnet(arch, block, layers, pretrained, progress, **kwargs):\n",
        "      model = ResNet(block, layers, **kwargs)\n",
        "      if pretrained:\n",
        "          state_dict = load_state_dict_from_url(model_urls[arch],\n",
        "                                                progress=progress)\n",
        "          model.load_state_dict(state_dict)\n",
        "      return model\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n",
        "    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n",
        "    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\n",
        "    # This variant is also known as ResNet V1.5 and improves accuracy according to\n",
        "    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n",
        "\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        width = int(planes * (base_width / 64.)) * groups\n",
        "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv1x1(inplanes, width)\n",
        "        self.bn1 = norm_layer(width)\n",
        "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
        "        self.bn2 = norm_layer(width)\n",
        "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
        "        self.bn3 = norm_layer(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        \n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        \n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckJO12iNuNBC"
      },
      "source": [
        "'''\n",
        "For BERT\n",
        "'''\n",
        "from transformers import DistilBertForSequenceClassification, AdamW, DistilBertConfig\n",
        "from transformers import get_linear_schedule_with_warmup"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHfFe7WDaP8k"
      },
      "source": [
        "**Device**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFeNpEoAaP8k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15fb26de-3dc3-4207-c1ce-58644f63be68"
      },
      "source": [
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "#gpu_ids = [7,6]\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9tV3N_haP8l"
      },
      "source": [
        "**Dataloading Scheme**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "T1L722dQ5QXM",
        "outputId": "50907143-7bf7-413b-b05f-348fa4767a22"
      },
      "source": [
        "import os\n",
        "os.getcwd()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/DL_PROJECT'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBPb5OqiaP8l"
      },
      "source": [
        "trainlist = '/content/drive/My Drive/DL_PROJECT/hateful_memes/hateful_memes/train.jsonl'\n",
        "validlist = '/content/drive/My Drive/DL_PROJECT/hateful_memes/hateful_memes/dev_seen.jsonl'"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYE7ZWHgaP8l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aa6a287-7eb2-4f23-8484-a21351e3dc40"
      },
      "source": [
        "'''\n",
        "Train Dataloader\n",
        "''' \n",
        "train_dataset = mydataset(trainlist,name='train')   #mydataset_captioning(trainlist,name='train')          \n",
        "train_dataloader = data.DataLoader(train_dataset, shuffle= True, batch_size = 8, num_workers=4,pin_memory=True)\n",
        "\n",
        "'''\n",
        "Validation Dataloader\n",
        "''' \n",
        "validation_dataset = mydataset(validlist, name='valid')  #mydataset_captioning(validlist, name='valid')         \n",
        "validation_dataloader = data.DataLoader(validation_dataset, shuffle=False, batch_size = 8, num_workers=4,pin_memory=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2190: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFqdxztfaP8m"
      },
      "source": [
        "**Model Definition**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxRnFreKaP8n"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        "    \n",
        "'''\n",
        "Model1 ResNet50\n",
        "'''\n",
        "#Image_model = ResNet(Bottleneck, [3, 4, 6, 3], num_classes = 2)\n",
        "#Image_model = nn.DataParallel(Image_model).to(device)\n",
        "#Model1 ResNeXt101_32x8d\n",
        "\n",
        "#Image_model = ResNet(Bottleneck, [3, 4, 6, 3], num_classes = 2)\n",
        "#Image_model = resnext101_32x8d()\n",
        "Image_model = wide_resnet101_2()\n",
        "#Image_model.fc = nn.Sequential(\n",
        "#    nn.Linear(Image_model.fc.in_features, 2)\n",
        "#    )\n",
        "\n",
        "Image_model = nn.DataParallel(Image_model).to(device)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AyJYW6haP8n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171,
          "referenced_widgets": [
            "101f450cf7314744bbfdb696b88a7d0e",
            "0770fc20e84a4f339a22362f24ea9d84",
            "be7b473be67b476ab7968a576e817bf0",
            "a6495f85f53348c38698518aea817e13",
            "9854974399564fa48966dba15e671706",
            "3aaa3f34b86c4892a59c56edaf929d6b",
            "fe3ccd6ccdf14fc59b3efcdceebe7419",
            "e61e84a2e96345f3add0338e874dcb40"
          ]
        },
        "outputId": "f0195a35-94c0-4127-a4e4-3d1788a9cd8c"
      },
      "source": [
        "'''\n",
        "Model 2 BERT\n",
        "\n",
        "Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top.\n",
        "''' \n",
        "\n",
        "Text_model = DistilBertForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\", \n",
        "    num_labels = 2,   \n",
        "    output_attentions = False, \n",
        "    output_hidden_states = True\n",
        ")\n",
        "\n",
        "Text_model = nn.DataParallel(Text_model).to(device)\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "101f450cf7314744bbfdb696b88a7d0e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=267967963.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3VLQHnuaP8o"
      },
      "source": [
        "#Fusion - Image Features, Text Features with Batch Normalization+Dropout\n",
        "\n",
        "class FusionNet(nn.Module):\n",
        "    \n",
        "    def __init__(self, num_classes, drop_prob = 0.1):\n",
        "        super(FusionNet, self).__init__()\n",
        "        \n",
        "        self.fc = nn.Linear(in_features=768+2048, out_features= 512)\n",
        "        \n",
        "        self.bn = nn.BatchNorm1d(512)\n",
        "        self.bn1 = nn.BatchNorm1d(768)\n",
        "        self.bn2 = nn.BatchNorm1d(2048)        \n",
        "        self.dropout = nn.Dropout(drop_prob)   \n",
        "        self.classify = nn.Linear(in_features = 512, out_features = num_classes)\n",
        "\n",
        "    def forward(self, text_features, image_features): #, caption_features):\n",
        "\n",
        "        text_features = self.bn1(text_features)\n",
        "        image_features = self.bn2(image_features)\n",
        "        #caption_features = self.bn3(caption_features)\n",
        "        fused_input =  torch.cat((text_features, image_features), dim=1)\n",
        "        x = self.fc(fused_input)\n",
        "        x = F.relu(self.bn(x))        \n",
        "        x = F.relu(self.classify(x)) \n",
        "        return x"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoY9KlUZZjPt"
      },
      "source": [
        "def plot_loss(epochs, train_loss, v_loss, title):\n",
        "    plt.figure(figsize=(8,8))\n",
        "    x = np.arange(1,epochs+2)\n",
        "    plt.plot(x, train_loss, label = 'Training Loss')\n",
        "    plt.plot(x, v_loss, label = 'Validation Loss')\n",
        "    plt.xlabel('Epochs', fontsize =16)\n",
        "    plt.ylabel('Loss', fontsize =16)\n",
        "    plt.title(title,fontsize =16)\n",
        "    plt.legend(fontsize=16)\n",
        "    \n",
        "    \n",
        "def plot_acc(epochs,v_acc):\n",
        "    plt.figure(figsize=(8,8))\n",
        "    x = np.arange(1,epochs+2)\n",
        "    plt.plot(x, v_acc)\n",
        "    plt.xlabel('Epochs', fontsize =16)\n",
        "    plt.ylabel('Validation Accuracy', fontsize =16)\n",
        "    plt.title('Validation Accuracy v/s Epochs',fontsize =16)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GT7YNizfH9r"
      },
      "source": [
        "train_loss= []\n",
        "v_loss = []\n",
        "v_acc = []\n",
        "\n",
        "def train(image_model,text_model,fusion_model,data_loader,test_loader,criterion,optimizer, lr_scheduler, modelpath, writer, device, epochs):\n",
        "    fusion_model.train()\n",
        "    for epoch in range(epochs):\n",
        "        avg_loss = 0.0\n",
        "                \n",
        "        \n",
        "        for batch_num, (feats, captions, input_id, attention_masks, target) in enumerate(data_loader):\n",
        "            \n",
        "            feats, target = feats.to(device), target.to(device)\n",
        "            input_ids, attention_masks = input_id.to(device), attention_masks.to(device)\n",
        "               \n",
        "            '''\n",
        "            Compute ResNet Features\n",
        "            '''\n",
        "            out, image_features = image_model(feats)\n",
        "                            \n",
        "            '''\n",
        "            Compute BERT Features\n",
        "            Take hidden state corresponding to [CLS] token from the final transformer\n",
        "            '''\n",
        "            output_dictionary = text_model(input_ids, \n",
        "                                           #token_type_ids=None, \n",
        "                                           attention_mask=attention_masks, \n",
        "                                           labels=target,\n",
        "                                           return_dict = True)\n",
        "            \n",
        "            text_features = output_dictionary.hidden_states[6][:,0,:]\n",
        "            \n",
        "            '''\n",
        "            Compute Classification Output and loss from Fusion model\n",
        "            '''\n",
        "            output = fusion_model(text_features, image_features)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            '''\n",
        "            Take Step\n",
        "            '''                    \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            avg_loss += loss.item()\n",
        "#             '''\n",
        "#             linear_schedule_with_warmup take step after each batch\n",
        "#             '''\n",
        "#             lr_scheduler.step()\n",
        "#             if batch_num % 100 == 99:\n",
        "#                 print('loss', avg_loss/100)\n",
        "                \n",
        "            del feats\n",
        "            del captions\n",
        "            del input_ids\n",
        "            del attention_masks\n",
        "            del target\n",
        "            del loss\n",
        "            \n",
        "            \n",
        "        training_loss = avg_loss/len(data_loader)\n",
        "       \n",
        "        print('Epoch: ', epoch+1)            \n",
        "        print('training loss = ', training_loss)\n",
        "        train_loss.append(training_loss)\n",
        "\n",
        "        \n",
        "        \n",
        "        '''\n",
        "        Learning rate scheduler\n",
        "        '''\n",
        "        lr_scheduler.step()\n",
        "            \n",
        "            \n",
        "        '''\n",
        "        Check performance on validation set after an Epoch\n",
        "        '''\n",
        "        \n",
        "        valid_loss, top1_acc= test_classify(image_model, text_model, fusion_model, test_loader, criterion, device)\n",
        "        print('Validation Loss: {:.4f}\\tTop 1 Validation Accuracy: {:.4f}'.format(valid_loss, top1_acc))\n",
        "        v_loss.append(valid_loss)\n",
        "        v_acc.append(top1_acc)\n",
        "\n",
        "        '''\n",
        "        Logs - For tensor Boradr - I am working on it!\n",
        "        '''\n",
        "        writer.add_scalar(\"Loss/train\", training_loss, epoch)            \n",
        "        writer.add_scalar('Loss/Validation', valid_loss, epoch)\n",
        "        writer.add_scalar('Accuracy/Validation', top1_acc, epoch)\n",
        "\n",
        "        \n",
        "'''\n",
        "Returns Loss and top1 accuracy on test/validation set\n",
        "'''\n",
        "def test_classify(image_model, text_model, fusion_model, test_loader, criterion, device):\n",
        "    fusion_model.eval()\n",
        "    test_loss = []\n",
        "    top1_accuracy = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_num, (feats, captions, input_id, attention_masks, target) in enumerate(test_loader):\n",
        "        \n",
        "        feats, target = feats.to(device), target.to(device)\n",
        "        input_ids, attention_masks = input_id.to(device), attention_masks.to(device)\n",
        "        \n",
        "        '''\n",
        "        Compute Resnext(Wide) Features\n",
        "        '''\n",
        "        out, image_features = image_model(feats) \n",
        "\n",
        "        '''\n",
        "        Compute BERT Features\n",
        "        '''\n",
        "        output_dictionary = text_model(input_ids, \n",
        "                                       #token_type_ids=None, \n",
        "                                       attention_mask=attention_masks, \n",
        "                                       labels=target,\n",
        "                                       return_dict = True)\n",
        "        text_features = output_dictionary.hidden_states[6][:,0,:]\n",
        "        \n",
        "        '''\n",
        "        Compute Classification Output and loss from Fusion model\n",
        "        '''\n",
        "        output = fusion_model(text_features, image_features)\n",
        "        loss = criterion(output, target)\n",
        "        test_loss.extend([loss.item()]*feats.size()[0])\n",
        "\n",
        "        '''\n",
        "        Prediction\n",
        "        '''\n",
        "        predictions = F.softmax(output, dim=1)\n",
        "        \n",
        "        _, top1_pred_labels = torch.max(predictions,1)\n",
        "        top1_pred_labels = top1_pred_labels.view(-1)\n",
        "        \n",
        "        top1_accuracy += torch.sum(torch.eq(top1_pred_labels, target)).item()\n",
        "        total += len(target)\n",
        "        \n",
        "        del feats\n",
        "        del captions\n",
        "        del input_ids\n",
        "        del attention_masks\n",
        "        del target\n",
        "        del loss\n",
        "            \n",
        "    fusion_model.train()\n",
        "    return np.mean(test_loss), top1_accuracy/total"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85pRXktUaP8o"
      },
      "source": [
        "Fusion_model = FusionNet(num_classes = 2 , drop_prob = 0.1)\n",
        "Fusion_model = nn.DataParallel(Fusion_model).to(device)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agClo63KaP8p"
      },
      "source": [
        "model_name = 'Early Fusion Model'\n",
        "model_path = '/content/drive/My Drive/DL_PROJECT/' +model_name"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I08ZjXbr0TMT"
      },
      "source": [
        "**Hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zLThvRyzU0E"
      },
      "source": [
        "'''\n",
        "Loss Function\n",
        "'''\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "'''\n",
        "Optimizer\n",
        "'''\n",
        "optimizer = torch.optim.SGD(Fusion_model.parameters(), lr=1e-3, weight_decay=1e-1, momentum=0.9)\n",
        "#optimizer = AdamW(Fusion_model.parameters(), lr = 2e-3, eps = 1e-8)\n",
        "\n",
        "'''\n",
        "Number of training epochs.\n",
        "'''\n",
        "num_Epochs = 2\n",
        "\n",
        "\n",
        "# '''\n",
        "# OneCycleLR\n",
        "# '''\n",
        "# max_lr = 0.05\n",
        "# lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, total_steps=None, epochs=num_Epochs, steps_per_epoch=len(train_dataloader), pct_start=0.3, anneal_strategy='cos', cycle_momentum=True, base_momentum=0.85, max_momentum=0.95, div_factor=25.0, final_div_factor=10000.0, last_epoch=-1)\n",
        "\n",
        "\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size= 4, gamma = 0.1)\n",
        "\n",
        "# lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max, eta_min=0, last_epoch=-1)"
      ],
      "execution_count": 402,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRynP2D3VVIT",
        "outputId": "419c40e8-3f5d-40bf-f2e7-8c4a9f4c3705"
      },
      "source": [
        "#torch.cuda.memory_summary(device=None, abbreviated=False)\n",
        "torch.cuda.empty_cache()\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter(model_name)\n",
        "\n",
        "train(Image_model, Text_model, Fusion_model, train_dataloader, validation_dataloader, criterion, optimizer, lr_scheduler, model_path, writer, device, epochs = num_Epochs)\n",
        "\n",
        "writer.flush()\n",
        "writer.close()"
      ],
      "execution_count": 403,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  1\n",
            "training loss =  0.5780134111614802\n",
            "Validation Loss: 0.6898\tTop 1 Validation Accuracy: 0.5700\n",
            "Epoch:  2\n",
            "training loss =  0.5895192897050647\n",
            "Validation Loss: 0.7338\tTop 1 Validation Accuracy: 0.5140\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZY-h3UtaP8q"
      },
      "source": [
        "**Evaluate**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzTSBs4SaP8q"
      },
      "source": [
        "**Predict on Test and generate output.csv**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQM4UyDkaP8r"
      },
      "source": [
        "**Test Dataloader**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHDvADPBaP8r"
      },
      "source": [
        "testlist = '/content/drive/My Drive/DL_PROJECT/hateful_memes/hateful_memes/test_seen.jsonl'\n",
        "\n",
        "#test_dataset = mytestdataset(testlist, name='test')          \n",
        "#test_dataloader = data.DataLoader(test_dataset, shuffle= False, batch_size = 8, num_workers=4,pin_memory=True)"
      ],
      "execution_count": 404,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0x2zuCGiMRj",
        "outputId": "be23042e-7f2e-4f01-e24d-d8689df61469"
      },
      "source": [
        "#test_dataset = mydataset(testlist, name='test')          \n",
        "#test_dataloader = data.DataLoader(test_dataset, shuffle= False, batch_size = 8, num_workers=4,pin_memory=True)\n",
        "#test_classify(Image_model, Text_model, Fusion_model, test_dataloader, criterion, device)\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2190: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7942226231098175, 0.553)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVhpdpPKJv2-",
        "outputId": "4ac75c82-62b9-449a-8d27-0033a3a461fc"
      },
      "source": [
        "test_dataset = mytestdataset(testlist, name='test')          \n",
        "test_dataloader = data.DataLoader(test_dataset, shuffle= False, batch_size = 8, num_workers=4,pin_memory=True)\n",
        "#test_classify(Image_model, Text_model, Fusion_model, test_dataloader, criterion, device)\n"
      ],
      "execution_count": 405,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2190: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4bWlTSoHpJ6"
      },
      "source": [
        "import csv\n",
        "\n",
        "def predict(image_model, text_model, fusion_model, test_dataloader, device):\n",
        "    \n",
        "    image_model.eval()\n",
        "    text_model.eval()\n",
        "    fusion_model.eval()\n",
        "\n",
        "    with open('output.csv',mode='w') as output_file:\n",
        "        \n",
        "        f=csv.writer(output_file,delimiter=',')\n",
        "        f.writerow(['id','proba', 'label'])\n",
        "\n",
        "\n",
        "        for batch_num, (feats, captions, input_ids, attention_masks,image_names) in enumerate(test_dataloader):\n",
        "        \n",
        "            feats = feats.to(device)\n",
        "            input_ids, attention_masks = input_ids.to(device), attention_masks.to(device)\n",
        "            #input_ids_cap, attention_masks_cap = input_ids_cap.to(device), attention_masks_cap.to(device)\n",
        "\n",
        "            '''\n",
        "            Compute ResNet Features\n",
        "            '''\n",
        "            out, image_features = image_model(feats) \n",
        "\n",
        "            \n",
        "            '''\n",
        "            Compute BERT Features for true captions\n",
        "            '''\n",
        "            output_dictionary = text_model(input_ids, \n",
        "                                           #token_type_ids=None, \n",
        "                                           attention_mask=attention_masks, \n",
        "                                           #labels=target,\n",
        "                                           return_dict = True)\n",
        "\n",
        "            text_features = output_dictionary.hidden_states[6][:,0,:]\n",
        "\n",
        "            '''\n",
        "            Compute Classification Output and loss from Fusion model\n",
        "            '''\n",
        "            output = fusion_model(text_features, image_features)\n",
        "\n",
        "\n",
        "\n",
        "            '''\n",
        "            Prediction and Probabilities of Hatefulness\n",
        "            '''\n",
        "\n",
        "            predictions = F.softmax(output, dim=1)\n",
        "\n",
        "            proba = predictions.detach().cpu().numpy()\n",
        "\n",
        "            _, top1_pred_labels = torch.max(predictions,1)\n",
        "            top1_pred_labels.view(-1)\n",
        "                        \n",
        "\n",
        "                \n",
        "            for index,name in enumerate(list(image_names)):\n",
        "                f.writerow([str(name), proba[index][1], int(list(top1_pred_labels)[index].item())])"
      ],
      "execution_count": 406,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPoGZ1L0aP8r"
      },
      "source": [
        "#predict(image_model, text_model, fusion_model, test_dataloader, device)\n",
        "predict(Image_model, Text_model, Fusion_model, test_dataloader, device)"
      ],
      "execution_count": 407,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "6-rxOVzLWyEA",
        "outputId": "6680357c-238a-4d39-db74-674c2e376b11"
      },
      "source": [
        "import pandas as pd\n",
        "predicted = pd.read_csv('/content/drive/My Drive/DL_PROJECT/output.csv')\n",
        "\n",
        "predicted.head()"
      ],
      "execution_count": 408,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>proba</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16395</td>\n",
              "      <td>0.342958</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37405</td>\n",
              "      <td>0.401274</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>94180</td>\n",
              "      <td>0.379644</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>54321</td>\n",
              "      <td>0.421448</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>97015</td>\n",
              "      <td>0.526633</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id     proba  label\n",
              "0  16395  0.342958      0\n",
              "1  37405  0.401274      0\n",
              "2  94180  0.379644      0\n",
              "3  54321  0.421448      0\n",
              "4  97015  0.526633      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 408
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvcItXyTcpAB",
        "outputId": "02fa4b52-7b99-4fd0-bc65-0d7c2310c3a3"
      },
      "source": [
        "print(len(predicted))"
      ],
      "execution_count": 409,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oJflim_RCjv"
      },
      "source": [
        "pred_labels = {predicted['id'][i]:predicted['label'][i] for i in range(1000)}\n",
        "pred_prob = {predicted['id'][i]:predicted['proba'][i] for i in range(1000)}"
      ],
      "execution_count": 410,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ipUgleocN-XE",
        "outputId": "cfb9ba71-249a-4de6-c1d9-8554c72187db"
      },
      "source": [
        "valid = pd.read_json(testlist, lines=True)\n",
        "valid.head()"
      ],
      "execution_count": 411,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>img</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16395</td>\n",
              "      <td>img/16395.png</td>\n",
              "      <td>1</td>\n",
              "      <td>handjobs sold seperately</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37405</td>\n",
              "      <td>img/37405.png</td>\n",
              "      <td>1</td>\n",
              "      <td>introducing fidget spinner for women</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>94180</td>\n",
              "      <td>img/94180.png</td>\n",
              "      <td>1</td>\n",
              "      <td>happy pride month let's go beat up lesbians</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>54321</td>\n",
              "      <td>img/54321.png</td>\n",
              "      <td>1</td>\n",
              "      <td>laughs in [majority of u.s crime rate]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>97015</td>\n",
              "      <td>img/97015.png</td>\n",
              "      <td>1</td>\n",
              "      <td>finds out those 72 virgins.. are goats</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id            img  label                                         text\n",
              "0  16395  img/16395.png      1                     handjobs sold seperately\n",
              "1  37405  img/37405.png      1         introducing fidget spinner for women\n",
              "2  94180  img/94180.png      1  happy pride month let's go beat up lesbians\n",
              "3  54321  img/54321.png      1       laughs in [majority of u.s crime rate]\n",
              "4  97015  img/97015.png      1       finds out those 72 virgins.. are goats"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 411
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-du7CMEP7-V",
        "outputId": "ec921043-c12b-4195-b588-63efaf618030"
      },
      "source": [
        "# Ground truth labels\n",
        "actual = {valid['id'][i]:valid['label'][i] for i in range(500)}\n",
        "print(len(actual))\n",
        "print(len(valid))"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "wepfcBAQTo6_",
        "outputId": "62944e07-5553-4537-fed5-01f8b1336e9d"
      },
      "source": [
        "valid.set_index(\"id\", inplace=True)\n",
        "valid.head()"
      ],
      "execution_count": 412,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>img</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16395</th>\n",
              "      <td>img/16395.png</td>\n",
              "      <td>1</td>\n",
              "      <td>handjobs sold seperately</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37405</th>\n",
              "      <td>img/37405.png</td>\n",
              "      <td>1</td>\n",
              "      <td>introducing fidget spinner for women</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94180</th>\n",
              "      <td>img/94180.png</td>\n",
              "      <td>1</td>\n",
              "      <td>happy pride month let's go beat up lesbians</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54321</th>\n",
              "      <td>img/54321.png</td>\n",
              "      <td>1</td>\n",
              "      <td>laughs in [majority of u.s crime rate]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97015</th>\n",
              "      <td>img/97015.png</td>\n",
              "      <td>1</td>\n",
              "      <td>finds out those 72 virgins.. are goats</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 img  label                                         text\n",
              "id                                                                      \n",
              "16395  img/16395.png      1                     handjobs sold seperately\n",
              "37405  img/37405.png      1         introducing fidget spinner for women\n",
              "94180  img/94180.png      1  happy pride month let's go beat up lesbians\n",
              "54321  img/54321.png      1       laughs in [majority of u.s crime rate]\n",
              "97015  img/97015.png      1       finds out those 72 virgins.. are goats"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 412
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJXx4yTfNfUm"
      },
      "source": [
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sn\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "'''\n",
        "Return a Dictionary by it's values sorted in descending order\n",
        "'''\n",
        "def sorted_dict(unsorted_dictionary):\n",
        "    sorted_keys = sorted(unsorted_dictionary, key =unsorted_dictionary.__getitem__, reverse=True)\n",
        "\n",
        "    sorted_values = sorted(unsorted_dictionary.values(),reverse=True)\n",
        "\n",
        "    sorted_dictionary = {}\n",
        "    for i in range(len(sorted_keys)):\n",
        "        sorted_dictionary[sorted_keys[i]] = sorted_values[i]\n",
        "        \n",
        "    return sorted_dictionary\n",
        "'''\n",
        "Get AUROC score using sklearn.metrics.roc_auc_score\n",
        "'''\n",
        "def get_AUROC(actual, pred_labels):\n",
        "    \n",
        "    ytrue=[]\n",
        "    ypred=[]\n",
        "    for ids in list(actual.keys()):\n",
        "        ytrue.append(actual[ids])\n",
        "        ypred.append(pred_labels[ids])\n",
        "\n",
        "    AUROC_score = roc_auc_score(ytrue, ypred)\n",
        "    \n",
        "    return AUROC_score\n",
        "'''\n",
        "Get count of True Positives, False Positives, True Negatives, False Negatives\n",
        "'''\n",
        "def count(True_positives, True_negatives, False_positives,  False_negatives):\n",
        "    \n",
        "    tp = len(True_positives)\n",
        "    tn = len(True_negatives)\n",
        "    fp = len(False_positives)\n",
        "    fn = len(False_negatives)\n",
        "    total = tp+tn+fp+fn\n",
        "    \n",
        "    return tp,tn,fp,fn,total\n",
        "\n",
        "'''\n",
        "Returns True Positives, False Positives, True Negatives, False Negatives, AUROC_score\n",
        "'''\n",
        "def Statistics(actual, pred_labels, pred_prob, sorted_dict):\n",
        "    \n",
        "    #Correctly Predicted\n",
        "    True_positives = defaultdict(int)\n",
        "    True_negatives = defaultdict(int)\n",
        "\n",
        "\n",
        "    #Benign Meme but predicted hateful\n",
        "    False_positives = defaultdict(int)\n",
        "\n",
        "    # Hateful Meme, but predicted Benign\n",
        "    False_negatives = defaultdict(int)\n",
        "\n",
        "\n",
        "    \n",
        "    for ids in list(actual.keys()):\n",
        "\n",
        "        if actual[ids] != pred_labels[ids]:\n",
        "\n",
        "            if pred_prob[ids]>=0.5:\n",
        "                False_positives[ids] = pred_prob[ids]\n",
        "\n",
        "            else:\n",
        "                 False_negatives[ids] = pred_prob[ids]   \n",
        "\n",
        "\n",
        "        else:\n",
        "            if pred_prob[ids]>=0.5:\n",
        "                True_positives[ids] = pred_prob[ids]\n",
        "\n",
        "            else:\n",
        "                 True_negatives[ids] = pred_prob[ids]   \n",
        "            \n",
        "        \n",
        "    return sorted_dict(True_positives), sorted_dict(True_negatives), sorted_dict(False_positives),  sorted_dict(False_negatives)\n",
        "\n",
        "\n",
        "'''\n",
        "Plots Confusion Matrix\n",
        "'''\n",
        "def plot_confusion_matrix(tn, fp, fn, tp, AUROC_score,total):\n",
        "    \n",
        "    \n",
        "    matrix = np.array(([tn, fp],[fn,tp]))\n",
        "    percent = (matrix/matrix.sum())*100\n",
        "    \n",
        "    accuracy = ((tp+tn)/total)*100\n",
        "    Precision = (tp/(tp+fp))*100\n",
        "    Recall = (tp/(tp+fn))*100\n",
        "    F1_score =  2 * (Precision * Recall) / (Precision + Recall)\n",
        "    \n",
        "    \n",
        "    df_cm = pd.DataFrame(matrix, ['Peaceful','Hateful'], ['Peaceful','Hateful'])\n",
        "    text = np.asarray([['TN', 'FP'], ['FN', 'TP']]) #np.asarray([['True Negatives', 'False Positives'], ['False Negatives', 'True Positives']])\n",
        "    label = (np.asarray([\"{0}\\n\\n{1}\\n\\n{2: .2f}%\".format(text,matrix,percent) for text, matrix, percent in zip(text.flatten(), matrix.flatten(), percent.flatten())])).reshape(2,2)\n",
        "    \n",
        "    plt.figure(figsize=(8,8))\n",
        "    sn.set(font_scale=2)\n",
        "    sn.heatmap(df_cm, annot=label, annot_kws={\"size\": 16}, cbar_kws={\"orientation\": \"horizontal\"},linewidths=1.0, fmt ='', cmap ='Greens')\n",
        "    \n",
        "    plt.title('Confusion Matrix', fontsize=16)\n",
        "    plt.text(0, 0, 'Accuracy: '+ str(round(accuracy,2)) +'       ' + 'AUROC:'+ str(round(AUROC_score,2)) +\n",
        "            '\\nPrecision: '+str(round(Precision,2)) + '     Recall: '+str(round(Recall,2)), fontsize=14,horizontalalignment='right',verticalalignment='top')\n",
        "    plt.show()\n"
      ],
      "execution_count": 413,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKPJ8ZlpNIoG"
      },
      "source": [
        "True_positives, True_negatives, False_positives,  False_negatives =  Statistics(actual, pred_labels, pred_prob, sorted_dict)\n"
      ],
      "execution_count": 414,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcnCMguVQnUT",
        "outputId": "2443afb3-4e8c-4bc6-85e7-f1c0dd5f1422"
      },
      "source": [
        "tp,tn,fp,fn,total = count(True_positives, True_negatives, False_positives,  False_negatives)\n",
        "accuracy = ((tp+tn)/total)*100\n",
        "print('Accuracy: ', accuracy)\n",
        "AUROC = get_AUROC(actual, pred_labels)\n",
        "print('AUROC: ',AUROC)\n",
        "#plot_confusion_matrix(tn, fp, fn, tp, AUROC_score, total)"
      ],
      "execution_count": 417,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  52.400000000000006\n",
            "AUROC:  0.5369658530335063\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_wQSJQxvAtE"
      },
      "source": [
        "def open_image(path, actual, pred_labels, pred_prob):\n",
        "    label_dict = {0:'Peaceful', 1:'Hateful'}\n",
        "\n",
        "    ground_truth = label_dict[actual[image_id]]\n",
        "    predicted_label = label_dict[pred_labels[image_id]]\n",
        "    confidence = pred_prob[image_id]\n",
        "    \n",
        "    image = Image.open('/content/drive/My Drive/DL_PROJECT/hateful_memes/hateful_memes/'+path)\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.axis('off')"
      ],
      "execution_count": 420,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbZEpV3gvGKu"
      },
      "source": [
        "#path = valid.loc[list(False_positives.keys())[0]]['img']\n",
        "#image_id = list(False_positives.keys())[0]\n",
        "#open_image(path, actual, pred_labels, pred_prob)"
      ],
      "execution_count": 418,
      "outputs": []
    }
  ]
}